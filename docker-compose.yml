version: "3.8"

services:
  # Main development container.
  devcontainer:
    image: "mcr.microsoft.com/devcontainers/universal:3-noble"
    volumes:
      - ../..:/workspaces:cached

      # Host directory mounts for persistent data across container rebuilds
      # adjust paths as needed for your project structure.

      # Mount as read-only to prevent accidental modification of host SSH keys.
      - ${HOME}/.ssh:/home/marcelo/.ssh-from-host:ro

      # GitHub CLI credentials for seamless GitHub integration.
      - ${HOME}/.config/gh:/home/marcelo/.config/gh:cached

      # Gemini CLI credentials for AI assistance tools.
      - ${HOME}/.gemini:/home/marcelo/.gemini:cached

      # Claude credentials and configuration for AI development tools.
      - ${HOME}/.claude:/home/marcelo/.claude:cached
      - ${HOME}/.claude.json:/home/marcelo/.claude.json:cached

      # Ollama models - persist downloaded models on host system.
      - ${HOME}/.ollama:/home/marcelo/.ollama:cached
    environment:
      - TZ=America/Sao_Paulo
      - LC_ALL=en_US.UTF-8
      - LANG=en_US.UTF-8
      # Point to Ollama service if enabled.
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      - ollama
    networks:
      - dev-network
    hostname: automaton
    command: sleep infinity
    profiles:
      - with-ollama

  # Minimal devcontainer without Ollama dependency.

  # Ollama for local AI/LLM development.
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
      # Mount host ollama folder to persist models across containers.
      - ${HOME}/.ollama:/root/.ollama-host:cached
    networks:
      - dev-network
    environment:
      # Use host GPU if available (Windows with NVIDIA, or Linux with proper setup).
      - NVIDIA_VISIBLE_DEVICES=all
    # GPU support - automatically enabled if NVIDIA runtime is available.
    # Works on Windows with Docker Desktop + NVIDIA, may need setup on Linux.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Fallback command if GPU support fails.

    profiles: [with-ollama, gpu]

  # Ollama CPU-only fallback (use when GPU not available).
  ollama-cpu:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
      # Mount host ollama folder to persist models across containers.
      - ${HOME}/.ollama:/root/.ollama-host:cached
    networks:
      - dev-network
    profiles: [with-ollama, cpu]

  # Database services (commented out by default - uncomment as needed)

  # # PostgreSQL for database experiments
  # postgres:
  #   image: postgres:16-alpine
  #   environment:
  #     - POSTGRES_DB=devdb
  #     - POSTGRES_USER=marcelo
  #     - POSTGRES_PASSWORD=devpass
  #   ports:
  #     - "5432:5432"
  #   volumes:
  #     - postgres-data:/var/lib/postgresql/data
  #     - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
  #   networks:
  #     - dev-network

  # # Redis for caching experiments
  # redis:
  #   image: redis:7-alpine
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - redis-data:/data
  #   networks:
  #     - dev-network

  # # MongoDB for document database experiments
  # mongodb:
  #   image: mongo:7
  #   environment:
  #     - MONGO_INITDB_ROOT_USERNAME=marcelo
  #     - MONGO_INITDB_ROOT_PASSWORD=devpass
  #   ports:
  #     - "27017:27017"
  #   volumes:
  #     - mongodb-data:/data/db
  #   networks:
  #     - dev-network
  #   profiles:
  #     - full  # Only start with --profile full

  # # MinIO for S3-compatible object storage experiments
  # minio:
  #   image: minio/minio:latest
  #   command: server /data --console-address ":9001"
  #   environment:
  #     - MINIO_ROOT_USER=marcelo
  #     - MINIO_ROOT_PASSWORD=devpassword123
  #   ports:
  #     - "9000:9000"   # API
  #     - "9001:9001"   # Console
  #   volumes:
  #     - minio-data:/data
  #   networks:
  #     - dev-network
  #   profiles:
  #     - full

volumes:
  ollama-data:
  # Uncomment database volumes as needed
  # postgres-data:
  # redis-data:
  # mongodb-data:
  # minio-data:

networks:
  dev-network:
    driver: bridge
